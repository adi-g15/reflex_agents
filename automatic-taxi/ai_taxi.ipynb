{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb4eb8d2-5535-44aa-a296-f4404e3cb550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "acbf546b-b6f5-4f7a-bf43-aa59db417048",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoTaxi:\n",
    "    is_ai=True\n",
    "\n",
    "    def __init__(self, agent_class, environ, start_loc, end_loc):\n",
    "        self.environ = environ\n",
    "\n",
    "        # Invariant: x,y is inside environ bounds for both start_loc & end_loc\n",
    "        self.start_loc = start_loc\n",
    "        self.end_loc = end_loc\n",
    "        \n",
    "        self.position = self.start_loc\n",
    "\n",
    "        self.agent = agent_class(self)\n",
    "        \n",
    "    def move_next(self):\n",
    "        action = self.agent.act( self.environ )\n",
    "        \n",
    "        # Now actuator, after getting action from the agent\n",
    "        self._move(direction=action)\n",
    "        \n",
    "    # Invariant: direction is valid (ie. not cross border)\n",
    "    def _move(self, direction):\n",
    "        if direction[0] == 0 and direction[1] == 0:\n",
    "            print(\"[\", self.agent, \"] Not Moving\")\n",
    "            return\n",
    "\n",
    "        print(\"[\",self.agent,\"] Taxi moving\", end=\" \")\n",
    "        if direction[0] == -1:\n",
    "            print(\"Left\", end=\" \")\n",
    "        elif direction[0] == 1:\n",
    "            print(\"Right\", end=\" \")\n",
    "        if direction[1] == -1:\n",
    "            print(\"Up\", end=\" \")\n",
    "        elif direction[1] == 1:\n",
    "            print(\"Down\", end=\" \")\n",
    "        print()\n",
    "\n",
    "        new_x = self.position[0] + direction[0]\n",
    "        new_y = self.position[1] + direction[1]\n",
    "\n",
    "        self.position = [ new_x, new_y ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2785d270-c200-45fb-9f38-642a5cb19a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model-based reflex agent\n",
    "class ModelBasedReflexAgent:\n",
    "    def __init__(self,parent_taxi):\n",
    "        self.taxi = parent_taxi\n",
    "        # At a time, it keeps notice of what nearby obstacles are present\n",
    "        # In this simple model, I am considering the obstacles to be the model data, as depending on what area are movable it will move (state.obstacle is for next move itself)\n",
    "        self.state = {\n",
    "            \"end_loc\": self.taxi.end_loc,\n",
    "            \"obstacles\": []\n",
    "        }\n",
    "\n",
    "    def _state_update(self):\n",
    "        curr_pos = self.taxi.position\n",
    "        environ = self.taxi.environ\n",
    "        obstacles = []\n",
    "\n",
    "        # Taxi can change it's destination at runtime, so we keep model's state coherent\n",
    "        self.state[\"end_loc\"] = self.taxi.end_loc\n",
    "        \n",
    "        dirs = [[-1,-1],[-1,0],[-1,1],[0,-1],[0,1],[1,-1],[1,0],[1,1]]\n",
    "        for dir in dirs:\n",
    "            x = curr_pos[0] + dir[0]\n",
    "            y = curr_pos[1] + dir[1]\n",
    "            if environ.matrix[x][y].is_blocked:\n",
    "                obstacles.append([x,y])\n",
    "\n",
    "        self.state[\"obstacles\"] = obstacles\n",
    "\n",
    "    def act(self,percept):\n",
    "        # The state <- Update-State() line in ppt slide, as per the simple model, that NEXT MOVE DEPENDS ON WHAT MOVABLE LOCATION IS\n",
    "        self._state_update()\n",
    "\n",
    "        pos = self.taxi.position\n",
    "\n",
    "        if pos == self.state[\"end_loc\"]:\n",
    "            print(\"[\",self,\"] ALREADY REACHED DESTINATION...\")\n",
    "            return [0,0]\n",
    "\n",
    "        movable_directions = []\n",
    "        \n",
    "        dirs = [[-1,-1],[-1,0],[-1,1],[0,-1],[0,1],[1,-1],[1,0],[1,1]]\n",
    "        \n",
    "        for dir in dirs:\n",
    "            x = pos[0] + dir[0]\n",
    "            y = pos[1] + dir[1]\n",
    "\n",
    "            # TODO\n",
    "            if x < 0 or x >= len(self.taxi.environ.matrix) or y < 0 or y >= len(self.taxi.environ.matrix):\n",
    "                continue\n",
    "\n",
    "            if [x,y] not in self.state[\"obstacles\"]:\n",
    "                movable_directions.append(dir)\n",
    "\n",
    "        # HERE IS WHERE a Goal-Based Reflex agent will perform better\n",
    "        # Instead of randomly chosing it will chose the location that gets us near to goal\n",
    "        return random.choice(movable_directions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e770769d-394d-4e55-a76c-7a45f46a5fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goal-based reflex agent\n",
    "\n",
    "# Sir my understanding is that Goal based agent is kind of Model-based + chose best move among possible moves/actions\n",
    "# so assuming that, it is mostly same, except some additions in Agent.act function\n",
    "class GoalBasedReflexAgent:\n",
    "    def __init__(self,parent_taxi):\n",
    "        self.taxi = parent_taxi\n",
    "        self.state = {\n",
    "            \"goal\": self.taxi.end_loc,\n",
    "            \"obstacles\": []\n",
    "        }\n",
    "\n",
    "    def _state_update(self):\n",
    "        curr_pos = self.taxi.position\n",
    "        environ = self.taxi.environ\n",
    "        obstacles = []\n",
    "\n",
    "        # Taxi can change it's destination at runtime, so we keep model's state coherent\n",
    "        self.state[\"goal\"] = self.taxi.end_loc\n",
    "        \n",
    "        dirs = [[-1,-1],[-1,0],[-1,1],[0,-1],[0,1],[1,-1],[1,0],[1,1]]\n",
    "        for dir in dirs:\n",
    "            x = curr_pos[0] + dir[0]\n",
    "            y = curr_pos[1] + dir[1]\n",
    "            if environ.matrix[x][y].is_blocked:\n",
    "                obstacles.append([x,y])\n",
    "\n",
    "        self.state[\"obstacles\"] = obstacles\n",
    "\n",
    "    def act(self,percept):\n",
    "        # The state <- Update-State() line in ppt slide, as per the simple model, that NEXT MOVE DEPENDS ON WHAT MOVABLE LOCATION IS\n",
    "        self._state_update()\n",
    "\n",
    "        movable_directions = []\n",
    "        \n",
    "        dirs = [[-1,-1],[-1,0],[-1,1],[0,-1],[0,1],[1,-1],[1,0],[1,1]]\n",
    "        pos = self.taxi.position\n",
    "        \n",
    "        if pos == self.state[\"goal\"]:\n",
    "            print(\"[\",self,\"] ALREADY REACHED DESTINATION...\")\n",
    "            return [0,0]\n",
    "\n",
    "        for dir in dirs:\n",
    "            x = pos[0] + dir[0]\n",
    "            y = pos[1] + dir[1]\n",
    "            if [x,y] not in self.state[\"obstacles\"]:\n",
    "                movable_directions.append(dir)\n",
    "\n",
    "        # Instead of randomly chosing it will chose the location that gets us near to goal\n",
    "\n",
    "        # Chose the direction that will get us closer to goal\n",
    "        better_direction = [0,0]\n",
    "        goal = self.state[\"goal\"]\n",
    "        for dir in movable_directions:\n",
    "            x = pos[0] + dir[0]\n",
    "            y = pos[1] + dir[1]\n",
    "            nearer_x = pos[0] + better_direction[0]\n",
    "            nearer_y = pos[1] + better_direction[1]\n",
    "            \n",
    "            # https://stackoverflow.com/questions/5228383/how-do-i-find-the-distance-between-two-points#5228392\n",
    "            nearest_dist = math.hypot( goal[1] - nearer_y, goal[0] - nearer_x )\n",
    "            new_dist = math.hypot( goal[1] - y, goal[0] - x )\n",
    "\n",
    "            if new_dist <= nearest_dist:\n",
    "                better_direction = dir\n",
    "\n",
    "        return better_direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ceb3b571-ca48-43d7-abf5-9a7085046e2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.AutoTaxi at 0x7f28ba3ce8e0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoTaxi(\n",
    "        agent_class=ModelBasedReflexAgent,\n",
    "        environ=[],\n",
    "        start_loc=[5,4],  # this can be any random position inside the world\n",
    "        end_loc=[15,17]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f927de5-9e1b-41a0-b625-c87fef1ebd84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.AutoTaxi at 0x7f28ba3cedc0>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AutoTaxi(\n",
    "        agent_class=GoalBasedReflexAgent,\n",
    "        environ=[],\n",
    "        start_loc=[2,9],\n",
    "        end_loc=[17,1]\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
